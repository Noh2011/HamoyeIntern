{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning: Classification - Managing the Quality Metric of Global Ecological Footprint\n",
    "\n",
    "# Stage-C-Lesson-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import important libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Url of the dataset\n",
    "url = 'https://query.data.world/s/wh6j7rxy2hvrn4ml75ci62apk5hgae'\n",
    "\n",
    "# read the dataset \n",
    "df = pd.read_csv(url, low_memory=False)\n",
    "# then save the df to the local machine for offline use\n",
    "df.to_csv('ecological_footprint_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>country_code</th>\n",
       "      <th>record</th>\n",
       "      <th>crop_land</th>\n",
       "      <th>grazing_land</th>\n",
       "      <th>forest_land</th>\n",
       "      <th>fishing_ground</th>\n",
       "      <th>built_up_land</th>\n",
       "      <th>carbon</th>\n",
       "      <th>total</th>\n",
       "      <th>QScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>AreaPerCap</td>\n",
       "      <td>0.140292</td>\n",
       "      <td>0.199546</td>\n",
       "      <td>0.097188051</td>\n",
       "      <td>0.036888</td>\n",
       "      <td>0.029320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.032351e-01</td>\n",
       "      <td>3A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>AreaTotHA</td>\n",
       "      <td>483000.000000</td>\n",
       "      <td>687000.000000</td>\n",
       "      <td>334600</td>\n",
       "      <td>127000.000000</td>\n",
       "      <td>100943.000800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.732543e+06</td>\n",
       "      <td>3A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>BiocapPerCap</td>\n",
       "      <td>0.159804</td>\n",
       "      <td>0.135261</td>\n",
       "      <td>0.084003213</td>\n",
       "      <td>0.013742</td>\n",
       "      <td>0.033398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.262086e-01</td>\n",
       "      <td>3A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>BiocapTotGHA</td>\n",
       "      <td>550176.242700</td>\n",
       "      <td>465677.972200</td>\n",
       "      <td>289207.1078</td>\n",
       "      <td>47311.551720</td>\n",
       "      <td>114982.279300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.467355e+06</td>\n",
       "      <td>3A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>EFConsPerCap</td>\n",
       "      <td>0.387510</td>\n",
       "      <td>0.189462</td>\n",
       "      <td>1.26E-06</td>\n",
       "      <td>0.004165</td>\n",
       "      <td>0.033398</td>\n",
       "      <td>1.114093</td>\n",
       "      <td>1.728629e+00</td>\n",
       "      <td>3A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  year  country_code        record      crop_land   grazing_land  \\\n",
       "0  Armenia  1992             1    AreaPerCap       0.140292       0.199546   \n",
       "1  Armenia  1992             1     AreaTotHA  483000.000000  687000.000000   \n",
       "2  Armenia  1992             1  BiocapPerCap       0.159804       0.135261   \n",
       "3  Armenia  1992             1  BiocapTotGHA  550176.242700  465677.972200   \n",
       "4  Armenia  1992             1  EFConsPerCap       0.387510       0.189462   \n",
       "\n",
       "   forest_land  fishing_ground  built_up_land    carbon         total QScore  \n",
       "0  0.097188051        0.036888       0.029320  0.000000  5.032351e-01     3A  \n",
       "1       334600   127000.000000  100943.000800  0.000000  1.732543e+06     3A  \n",
       "2  0.084003213        0.013742       0.033398  0.000000  4.262086e-01     3A  \n",
       "3  289207.1078    47311.551720  114982.279300  0.000000  1.467355e+06     3A  \n",
       "4     1.26E-06        0.004165       0.033398  1.114093  1.728629e+00     3A  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the local csv file\n",
    "data = pd.read_csv('ecological_footprint_data.csv', low_memory=False)\n",
    "# Explore the first five rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Classification and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3A    51481\n",
       "2A    10576\n",
       "2B    10096\n",
       "1B       16\n",
       "1A       16\n",
       "Name: QScore, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the distribution of target variable (QScore)\n",
    "data['QScore'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country               0\n",
       "year                  0\n",
       "country_code          0\n",
       "record                0\n",
       "crop_land         20472\n",
       "grazing_land      20472\n",
       "forest_land       20472\n",
       "fishing_ground    20473\n",
       "built_up_land     20473\n",
       "carbon            20473\n",
       "total                 9\n",
       "QScore                1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values of each column\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country           0\n",
       "year              0\n",
       "country_code      0\n",
       "record            0\n",
       "crop_land         0\n",
       "grazing_land      0\n",
       "forest_land       0\n",
       "fishing_ground    0\n",
       "built_up_land     0\n",
       "carbon            0\n",
       "total             0\n",
       "QScore            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For simplicity, we will drop the rows with missing values\n",
    "data = data.dropna()\n",
    "# Check again missing values of columns\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An obvious change in our target variable after removing the missing values is that there are only three classes left and from the distribution of the 3 classes, we can see that there is an obvious imbalance between the classes. There are methods that can be applied to handle this imbalance such as oversampling and undersampling.\n",
    "\n",
    "Oversampling involves increasing the number of instances in the class with fewer instances while undersampling involves reducing the data points in the class with more instances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3A    51473\n",
       "2A      224\n",
       "1A       16\n",
       "Name: QScore, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['QScore'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we will convert this to a binary classification problem by combining class '2A' and '1A'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3A    51473\n",
       "2A      240\n",
       "Name: QScore, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['QScore'] = data['QScore'].replace(['1A'], ['2A'])\n",
    "data['QScore'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>country_code</th>\n",
       "      <th>record</th>\n",
       "      <th>crop_land</th>\n",
       "      <th>grazing_land</th>\n",
       "      <th>forest_land</th>\n",
       "      <th>fishing_ground</th>\n",
       "      <th>built_up_land</th>\n",
       "      <th>carbon</th>\n",
       "      <th>total</th>\n",
       "      <th>QScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>AreaPerCap</td>\n",
       "      <td>2.072989e-01</td>\n",
       "      <td>8.112722e-01</td>\n",
       "      <td>0.048357265</td>\n",
       "      <td>0.022585</td>\n",
       "      <td>2.998367e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.119497e+00</td>\n",
       "      <td>2A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>AreaTotHA</td>\n",
       "      <td>8.417600e+06</td>\n",
       "      <td>3.294260e+07</td>\n",
       "      <td>1963600</td>\n",
       "      <td>917100.000000</td>\n",
       "      <td>1.217520e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.545842e+07</td>\n",
       "      <td>2A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>BiocapPerCap</td>\n",
       "      <td>2.021916e-01</td>\n",
       "      <td>2.636077e-01</td>\n",
       "      <td>0.027166736</td>\n",
       "      <td>0.007948</td>\n",
       "      <td>2.924496e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.301590e-01</td>\n",
       "      <td>2A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>BiocapTotGHA</td>\n",
       "      <td>8.210214e+06</td>\n",
       "      <td>1.070408e+07</td>\n",
       "      <td>1103135.245</td>\n",
       "      <td>322736.916200</td>\n",
       "      <td>1.187524e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.152769e+07</td>\n",
       "      <td>2A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>EFConsPerCap</td>\n",
       "      <td>6.280528e-01</td>\n",
       "      <td>1.810332e-01</td>\n",
       "      <td>0.162800822</td>\n",
       "      <td>0.014729</td>\n",
       "      <td>2.924496e-02</td>\n",
       "      <td>1.391455</td>\n",
       "      <td>2.407316e+00</td>\n",
       "      <td>2A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      country  year  country_code        record     crop_land  grazing_land  \\\n",
       "1536  Algeria  2016             4    AreaPerCap  2.072989e-01  8.112722e-01   \n",
       "1537  Algeria  2016             4     AreaTotHA  8.417600e+06  3.294260e+07   \n",
       "1538  Algeria  2016             4  BiocapPerCap  2.021916e-01  2.636077e-01   \n",
       "1539  Algeria  2016             4  BiocapTotGHA  8.210214e+06  1.070408e+07   \n",
       "1540  Algeria  2016             4  EFConsPerCap  6.280528e-01  1.810332e-01   \n",
       "\n",
       "      forest_land  fishing_ground  built_up_land    carbon         total  \\\n",
       "1536  0.048357265        0.022585   2.998367e-02  0.000000  1.119497e+00   \n",
       "1537      1963600   917100.000000   1.217520e+06  0.000000  4.545842e+07   \n",
       "1538  0.027166736        0.007948   2.924496e-02  0.000000  5.301590e-01   \n",
       "1539  1103135.245   322736.916200   1.187524e+06  0.000000  2.152769e+07   \n",
       "1540  0.162800822        0.014729   2.924496e-02  1.391455  2.407316e+00   \n",
       "\n",
       "     QScore  \n",
       "1536     2A  \n",
       "1537     2A  \n",
       "1538     2A  \n",
       "1539     2A  \n",
       "1540     2A  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2A = data[data.QScore == '2A']\n",
    "df_3A = data[data.QScore == '3A'].sample(350)\n",
    "\n",
    "data_df = df_2A.append(df_3A)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3A    350\n",
       "2A    240\n",
       "Name: QScore, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.utils\n",
    "data_df = sklearn.utils.shuffle(data_df, random_state=0)\n",
    "data_df = data_df.reset_index(drop=True)\n",
    "data_df.shape\n",
    "data_df['QScore'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the data and separate the target variable from feature variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>country_code</th>\n",
       "      <th>record</th>\n",
       "      <th>crop_land</th>\n",
       "      <th>grazing_land</th>\n",
       "      <th>forest_land</th>\n",
       "      <th>fishing_ground</th>\n",
       "      <th>built_up_land</th>\n",
       "      <th>carbon</th>\n",
       "      <th>total</th>\n",
       "      <th>QScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trinidad and Tobago</td>\n",
       "      <td>2016</td>\n",
       "      <td>220</td>\n",
       "      <td>AreaTotHA</td>\n",
       "      <td>4.700000e+04</td>\n",
       "      <td>7.000000e+03</td>\n",
       "      <td>236100</td>\n",
       "      <td>2.113600e+06</td>\n",
       "      <td>1.291780e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.404992e+06</td>\n",
       "      <td>2A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Belize</td>\n",
       "      <td>2016</td>\n",
       "      <td>23</td>\n",
       "      <td>EFProdPerCap</td>\n",
       "      <td>5.071023e-01</td>\n",
       "      <td>2.055006e-01</td>\n",
       "      <td>0.20984546</td>\n",
       "      <td>2.222697e+00</td>\n",
       "      <td>5.540510e-04</td>\n",
       "      <td>4.805086e-01</td>\n",
       "      <td>3.626208e+00</td>\n",
       "      <td>2A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Guatemala</td>\n",
       "      <td>2016</td>\n",
       "      <td>89</td>\n",
       "      <td>EFConsTotGHA</td>\n",
       "      <td>7.289958e+06</td>\n",
       "      <td>2.665859e+06</td>\n",
       "      <td>9354954.762</td>\n",
       "      <td>5.894037e+05</td>\n",
       "      <td>1.496289e+06</td>\n",
       "      <td>9.760726e+06</td>\n",
       "      <td>3.115719e+07</td>\n",
       "      <td>2A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Libyan Arab Jamahiriya</td>\n",
       "      <td>2006</td>\n",
       "      <td>124</td>\n",
       "      <td>EFConsPerCap</td>\n",
       "      <td>6.178304e-01</td>\n",
       "      <td>3.286547e-01</td>\n",
       "      <td>0.116582309</td>\n",
       "      <td>4.430471e-02</td>\n",
       "      <td>1.642221e-02</td>\n",
       "      <td>2.200892e+00</td>\n",
       "      <td>3.324687e+00</td>\n",
       "      <td>3A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kyrgyzstan</td>\n",
       "      <td>2016</td>\n",
       "      <td>113</td>\n",
       "      <td>EFConsPerCap</td>\n",
       "      <td>4.271284e-01</td>\n",
       "      <td>1.977978e-01</td>\n",
       "      <td>0.059306959</td>\n",
       "      <td>5.479879e-03</td>\n",
       "      <td>7.480447e-02</td>\n",
       "      <td>8.907022e-01</td>\n",
       "      <td>1.655220e+00</td>\n",
       "      <td>2A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  country  year  country_code        record     crop_land  \\\n",
       "0     Trinidad and Tobago  2016           220     AreaTotHA  4.700000e+04   \n",
       "1                  Belize  2016            23  EFProdPerCap  5.071023e-01   \n",
       "2               Guatemala  2016            89  EFConsTotGHA  7.289958e+06   \n",
       "3  Libyan Arab Jamahiriya  2006           124  EFConsPerCap  6.178304e-01   \n",
       "4              Kyrgyzstan  2016           113  EFConsPerCap  4.271284e-01   \n",
       "\n",
       "   grazing_land  forest_land  fishing_ground  built_up_land        carbon  \\\n",
       "0  7.000000e+03       236100    2.113600e+06   1.291780e+03  0.000000e+00   \n",
       "1  2.055006e-01   0.20984546    2.222697e+00   5.540510e-04  4.805086e-01   \n",
       "2  2.665859e+06  9354954.762    5.894037e+05   1.496289e+06  9.760726e+06   \n",
       "3  3.286547e-01  0.116582309    4.430471e-02   1.642221e-02  2.200892e+00   \n",
       "4  1.977978e-01  0.059306959    5.479879e-03   7.480447e-02  8.907022e-01   \n",
       "\n",
       "          total QScore  \n",
       "0  2.404992e+06     2A  \n",
       "1  3.626208e+00     2A  \n",
       "2  3.115719e+07     2A  \n",
       "3  3.324687e+00     3A  \n",
       "4  1.655220e+00     2A  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "590"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = data_df.drop(columns=['country', 'year', 'country_code'])\n",
    "len(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_df.drop(columns='QScore')\n",
    "y = data_df.QScore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3A    248\n",
       "2A    165\n",
       "Name: QScore, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the y_train\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is still an imbalance in the class distribution. For this, we use SMOTE \n",
    "only on the training data to handle this.\n",
    "\n",
    "In other way, there are categorical variables available, so that, we use LabelEncoder to encode categorical variables.\n",
    "\n",
    "Scikit-learn has a LabelEncoder class that can be used to get label encodings. We loop over the categorical variables and apply the label encoder separately to each column if we have more than one. But now we have only one categorical variable to encode is 'record'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, we should have to get list of categorical variables automatically to encode if any\n",
    "s = (X_train.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "\n",
    "X_train['forest_land'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/pandas/core/generic.py:5208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "# Encode categorical variable and transform it\n",
    "X_train.record = encoder.fit_transform(X_train.record)\n",
    "X_test.record = encoder.transform(X_test.record)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=1)\n",
    "X_train_balanced, y_train_balanced = smote.fit_sample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale using Min - Max scaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "normalised_train_df = scaler.fit_transform(X_train_balanced.drop(columns=['record']))\n",
    "normalised_train_df = pd.DataFrame(normalised_train_df, columns=X_train_balanced.drop(columns=['record']).columns)\n",
    "normalised_train_df['record'] = X_train_balanced['record']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the x_test using min-max scaler\n",
    "\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "normalised_test_df = scaler.transform(X_test.drop(columns=['record']))\n",
    "normalised_test_df = pd.DataFrame(normalised_test_df, columns=X_test.drop(columns=['record']).columns)\n",
    "normalised_test_df['record'] = X_test['record']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create LogisticRegression Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression()\n",
    "# Fit and train the model\n",
    "log_reg.fit(normalised_train_df, y_train_balanced)\n",
    "\n",
    "# Check\n",
    "#log_reg.__dict__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage-C-Lesson 2\n",
    "# Measuring Classification Performance\n",
    "\n",
    "Cross Validation techniques to evaluate the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4887218  0.48091696 0.39583583 0.56494635 0.53530612]\n",
      "Average score 49.315\n"
     ]
    }
   ],
   "source": [
    "# Performing cross validation\n",
    "# Import libararies\n",
    "from sklearn.metrics import recall_score, accuracy_score, precision_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(log_reg, normalised_train_df, y_train_balanced, cv=5, scoring='f1_macro')\n",
    "\n",
    "# printing scores\n",
    "print(scores)\n",
    "\n",
    "# Print average score\n",
    "print('Average score', round(scores.mean()*100, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix, Precision-Recall, ROC curve and the F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[41, 34],\n",
       "       [57, 45]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusiin Matrix\n",
    "new_predictions = log_reg.predict(normalised_test_df)\n",
    "cnf_mat = confusion_matrix(y_true=y_test, y_pred=new_predictions, labels=['2A', '3A'])\n",
    "cnf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 49.0\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=new_predictions)\n",
    "print('Accuracy: {}'.format(round(accuracy*100), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 42.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.41836734693877553"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision\n",
    "precision = precision_score(y_true=y_test, y_pred=new_predictions, pos_label='2A')\n",
    "print('Precision: {}'.format(round(precision*100), 2)) #prints 41.0\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 55.0\n"
     ]
    }
   ],
   "source": [
    "# Recall\n",
    "recall = recall_score(y_true=y_test, y_pred=new_predictions, pos_label='2A')\n",
    "print('Recall: {}'.format(round(recall*100), 2)) #prints 51.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 47.0\n"
     ]
    }
   ],
   "source": [
    "# F1-Score\n",
    "f1 = f1_score(y_true=y_test, y_pred=new_predictions, pos_label='2A')\n",
    "print('F1: {}'.format(round(f1*100), 2)) #prints 45.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58.39416058394161, 66.66666666666667, 52.23880597014925, 51.162790697674424, 0.0]\n",
      "Average score 45.692\n"
     ]
    }
   ],
   "source": [
    "# K-Fold Cross Validation\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5) # the training data is split into 5 equal groups\n",
    "kf.split(normalised_train_df)\n",
    "\n",
    "f1_scores = []\n",
    "# run for every split\n",
    "for train_index, test_index in kf.split(normalised_train_df):\n",
    "    x_train, x_test = normalised_train_df.iloc[train_index], normalised_train_df.iloc[test_index]\n",
    "    y_train, y_test = y_train_balanced.iloc[train_index], y_train_balanced.iloc[test_index]\n",
    "    \n",
    "    model = LogisticRegression().fit(x_train, y_train)\n",
    "    # Append result to the list\n",
    "    f1_scores.append(f1_score(y_true = y_test, y_pred=model.predict(x_test), pos_label='2A')*100)\n",
    "\n",
    "# print scores\n",
    "print(f1_scores)\n",
    "\n",
    "# Print average score\n",
    "print('Average score', round(np.array(f1_scores).mean(), 3))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51.85185185185185, 60.0, 50.505050505050505, 50.943396226415096, 58.2089552238806]\n",
      "Average score 54.302\n"
     ]
    }
   ],
   "source": [
    "# Using StratifiedKFold Cross Validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "f1_scores = []\n",
    "\n",
    "# run for every split\n",
    "for train_index, test_index in skf.split(normalised_train_df, y_train_balanced):\n",
    "    x_train, x_test = np.array(normalised_train_df)[train_index], np.array(normalised_train_df)[test_index]\n",
    "    y_train, y_test = y_train_balanced[train_index], y_train_balanced[test_index]\n",
    "    \n",
    "    model = LogisticRegression().fit(x_train, y_train)\n",
    "    # Save the result to list\n",
    "    f1_scores.append(f1_score(y_true=y_test, y_pred=model.predict(x_test), pos_label='2A')*100)\n",
    "\n",
    "# print f1_scores\n",
    "print(f1_scores)\n",
    "\n",
    "# Print average score\n",
    "print('Average score', round(np.array(f1_scores).mean(), 3))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score 44.355\n"
     ]
    }
   ],
   "source": [
    "# Leave One Out cross validation(LOOCV)\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "loo = LeaveOneOut()\n",
    "scores = cross_val_score(LogisticRegression(), normalised_train_df, y_train_balanced, cv=loo, scoring='f1_macro')\n",
    "\n",
    "# Print average score\n",
    "print('Average score', round(scores.mean()*100, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage-C-Lesson 4\n",
    "Tree-Based Methods and The Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dec_tree = DecisionTreeClassifier()\n",
    "# Fit the model\n",
    "dec_tree.fit(normalised_train_df, y_train_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
